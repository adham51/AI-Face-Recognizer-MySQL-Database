{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a539b6c-a56c-41a9-8549-5162de0f6589",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:42: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:42: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "C:\\Users\\Adham\\AppData\\Local\\Temp\\ipykernel_21884\\1307448787.py:42: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is (): # if faces is empty or did not read anything, return nothing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imporing libraries done\n"
     ]
    }
   ],
   "source": [
    "# This verion can be used to check if the project operates correctly or not without the use of MySQL\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "print(\"Imporing libraries done\")\n",
    "\n",
    "window = tk.Tk()\n",
    "window.title(\"Face Recognition system\")\n",
    "\n",
    "T = tk.Label(window, text=\"Facial Recognition System\", font=(\"Slab serif\",20))\n",
    "T.grid(column=1, row=0)\n",
    "\n",
    "Name = tk.Label(window, text=\"Name\", font=(\"Slab serif\",20))\n",
    "Name.grid(column=0, row=1)\n",
    "t1 = tk.Entry(window, width=50, bd=3)\n",
    "t1.grid(column=1, row=1)\n",
    " \n",
    "Age = tk.Label(window, text=\"Age\", font=(\"Slab serif\",20))\n",
    "Age.grid(column=0, row=2)\n",
    "t2 = tk.Entry(window, width=50, bd=3)\n",
    "t2.grid(column=1, row=2)\n",
    " \n",
    "Address = tk.Label(window, text=\"Address\", font=(\"Slab serif\",20))\n",
    "Address.grid(column=0, row=3)\n",
    "t3 = tk.Entry(window, width=50, bd=3)\n",
    "t3.grid(column=1, row=3)\n",
    "\n",
    "# After installing openCV using the pip install opencv-python command, we'll import the library\n",
    "def generate_dataset(): # Creating a function called generate dataset, since this is what will take user's face as input whenever we add a new user\n",
    "    if(t1.get()==\"\" or t2.get()==\"\" or t3.get()==\"\"):\n",
    "        messagebox.showinfo('Result', 'Please provide all details of the user')\n",
    "    else:\n",
    "        \n",
    "        face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\") #Input the cascade classifier which includes all what I was talking about in terms of how to detect face in general, haar-like feature, integral image, adaboost, and classifier cascades\n",
    "        def face_cropped(img): # This function is to help the computer read the user's face and give us back its coordinates\n",
    "            gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) # Conver Image from RGB colors to grey scale (from 0 to 255) with 0 being black and 255 being white and the number in between being grey\n",
    "            faces = face_classifier.detectMultiScale(gray, 1.2, 5) # Create a variable called faces to give us back 4 values (coordinates) from the function called detect multiscale. These values are the coordinates of the place where the person's face is located.\n",
    "            # scaling factor = 1.3, not sure I quite understand it but I think it's the size of the recantgle?! Parameter specifying how much the image size is reduced at each image scale. By rescaling the input image, you can resize a larger face to a smaller one, making it detectable by the algorithm. i.e. reduce the size by 5%, you increase the chance of a matching size with the model for detection is found.\n",
    "            # minimum neighbor = 5, I think it's how many weak classification or recatangles around the main one. Parameter specifying how many neighbours each candidate rectangle should have to retain it. This parameter will affect the quality of the detected faces. Higher value results in fewer detections but with higher quality. 3~6 is a good value for it.\n",
    "            if faces is (): # if faces is empty or did not read anything, return nothing\n",
    "                return None \n",
    "            for (x,y,w,h) in faces: \n",
    "                cropped_face = img[y:y+h,x:x+w] # X is the pixel of the x-axis on the screen and x+w is x-coordinate + width, giving us the 4 dimensions of the rectangle\n",
    "            return cropped_face\n",
    "    \n",
    "           \n",
    "        cap = cv2.VideoCapture(0) # 0 means access camera from laptop/webcam I think if 1 or -1 then it's external camera\n",
    "        id =10 # first authorized person, if second person give id=2\n",
    "        img_id = 0 # number of images for first authorized person\n",
    "        \n",
    "        while True: # After opening the camera, create a while loop that keeps taking pictures as long as face_cropped is true\n",
    "            ret, frame = cap.read() # frame refers to image i believe\n",
    "            if face_cropped(frame) is not None: # if the face_cropped function is acheived, we will make frame = to img. Make frame enter the face_cropped function and turn it into greyscale...etc.\n",
    "                img_id+=1 # save images with the following index user.1.img_id\n",
    "                face = cv2.resize(face_cropped(frame), (200,200)) #resize frame and store it into a variable called face. We resize because we want the downloaded picture to show a large view of your face\n",
    "                face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY) # turn face into grey scale\n",
    "                file_name_path = \"data/user.\"+str(id)+\".\"+str(img_id)+\".jpg\"\n",
    "                cv2.imwrite(file_name_path, face)\n",
    "                cv2.putText(face, str(img_id), (50,50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "                # (50,50) is the origin point from where text is going to be writte\n",
    "                # font scale = 1\n",
    "                # thinckness = 2\n",
    "                # font name is hershey complex\n",
    "                 \n",
    "                cv2.imshow(\"Cropped face\", face)\n",
    "                 \n",
    "            if cv2.waitKey(1)==13 or int(img_id)==200: #13 is the ASCII character of Enter key, so that when we press enter it stops or we reached 200 images \n",
    "                break\n",
    "        cap.release() # release camera not sure what it means\n",
    "        cv2.destroyAllWindows()\n",
    "        messagebox.showinfo('Result','Generating Dataset Completed')\n",
    "\n",
    " \n",
    "def train_classifier(): # Create a function that takes data directory (my collected data) located at directory of \"data\" file I created\n",
    "    data_dir = \"C:/Users/Adham/Desktop/Face Data\"\n",
    "    path = [os.path.join(data_dir, f) for f in os.listdir(data_dir)] # Make the path be data_dir path + the data_dir of the image after listing it and storing it in f\n",
    "    # for example, C:\\Users\\Adham\\Desktop\\Face recognizer\\data\\user.1.1\n",
    "    # for example, C:\\Users\\Adham\\Desktop\\Face recognizer\\data\\user.1.2...etc.\n",
    "     \n",
    "    faces = [] # create empty list\n",
    "    ids = [] \n",
    "     \n",
    "    for image in path:\n",
    "        img = Image.open(image).convert('L') # Change image to gray image\n",
    "        imageNp = np.array(img, 'uint8') # Change image to array format so we can split it\n",
    "        id = int(os.path.split(image)[1].split(\".\")[1])\n",
    "        # C:\\Users\\Adham\\Desktop\\Face recognizer\\data all of this is stored in array with idex [0]\n",
    "        # C:\\Users\\Adham\\Desktop\\Face recognizer\\data\\[0] user.1.1 this is index [1]\n",
    "        # After splitting index [1] by \".\" We'll have 3 index user[0], .1 [1], .1[2]\n",
    "        # Then, after splitting, we'll store the correspoding value of splitted index [1] in id value since it's the person's id\n",
    "         \n",
    "        faces.append(imageNp)\n",
    "        ids.append(id) # add id to the array called ids\n",
    "         \n",
    "    ids = np.array(ids)\n",
    "     \n",
    "    # Train and save classifier\n",
    "    clf = cv2.face.LBPHFaceRecognizer_create()\n",
    "    #clf = cv2.face.LBPHFaceRecognizer_create()\n",
    "    #clf = cv2.createLBPHFaceRecognizer()\n",
    "\n",
    "\n",
    "    clf.train(faces,ids) # train data \n",
    "    clf.write(\"classifier.xml\") # save data\n",
    "    messagebox.showinfo('Result','Training Dataset Completed')\n",
    "\n",
    "def detect_face(): \n",
    "    def draw_boundary(img, classifier, scaleFactor, minNeighbors, color, text, clf): #Create function to form a rectangle around the face\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # Turn image into grey scale image\n",
    "        features = classifier.detectMultiScale(gray_img, scaleFactor, minNeighbors) # detectMultiScale() method is commonly used from libraries \n",
    "        # like OpenCV to identify objects (such as faces) within an image. It utilizes the Haar-like features, integral imaging, creating classifier cascades  \n",
    "        # which detects objects at multiple scales in an image.\n",
    "         \n",
    "        for (x,y,w,h) in features:\n",
    "            cv2.rectangle(img, (x,y), (x+w,y+h), color, 2 ) # Create a rectangle around face with coordinates taken from features with color and thickness 2\n",
    "            # Takes into consideration real image not grey scale \n",
    "            id, pred = clf.predict(gray_img[y:y+h,x:x+w]) # Predict from grey scale image \n",
    "            # It is very important to note that this id is the one predicted by the classifier, not the one we put in the beginning\n",
    "            confidence = int(100*(1-pred/300)) # A formula to know whether my user is authorized or not according to my confidence value\n",
    "            \n",
    "            \n",
    "            if confidence>65:\n",
    "                if id==1: # First person in database \n",
    "                    cv2.putText(img, \"Adham\", (x,y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 1, cv2.LINE_AA) # Put text and all information on real image\n",
    "                if id==2: # First person in database \n",
    "                    cv2.putText(img, \"Adham Mask\", (x,y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 1, cv2.LINE_AA)\n",
    "                if id==3: # First person in database \n",
    "                    cv2.putText(img, \"Mansy\", (x,y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 1, cv2.LINE_AA)\n",
    "                if id==4: # First person in database \n",
    "                    cv2.putText(img, \"Eng. Kareem\", (x,y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 1, cv2.LINE_AA) # Put text and all information on real image\n",
    "                if id==5: # First person in database \n",
    "                    cv2.putText(img, \"Mashad\", (x,y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 1, cv2.LINE_AA) # Put text and all information on real image\n",
    "                if id==6: # First person in database \n",
    "                    cv2.putText(img, \"Ahmed Khaled\", (x,y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 1, cv2.LINE_AA) # Put text and all information on real image\n",
    "            else:\n",
    "                cv2.putText(img, \"Unknown Person\", (x,y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,255), 1, cv2.LINE_AA)\n",
    "         \n",
    "        return img\n",
    "     \n",
    "    # loading classifier\n",
    "    faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "     \n",
    "    clf = cv2.face.LBPHFaceRecognizer_create()\n",
    "    clf.read(\"classifier.xml\")\n",
    "     \n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "     \n",
    "    while True:\n",
    "        ret, img = video_capture.read()\n",
    "        img = draw_boundary(img, faceCascade, 1.3, 6, (255,255,255), \"Face\", clf)\n",
    "        cv2.imshow(\"face Detection\", img)\n",
    "         \n",
    "        if cv2.waitKey(1)==13: \n",
    "            break\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "b1 = tk.Button(window, text=\"Generate Dataset\", font=(\"Slab serif\",20), bg=\"pink\", fg=\"black\", command = generate_dataset)\n",
    "b1.grid(column=0, row=5)\n",
    "\n",
    "b2 = tk.Button(window, text=\"Training the Dataset\", font=(\"Slab serif\",20),bg=\"orange\",fg=\"black\", command = train_classifier )\n",
    "b2.grid(column=1, row=5)\n",
    " \n",
    "b3 = tk.Button(window, text=\"Detect Face\", font=(\"Slab serif\",20), bg=\"red\", fg=\"black\", command = detect_face)\n",
    "b3.grid(column=3, row=5)\n",
    " \n",
    "def message_box():\n",
    "    messagebox.showinfo(\"Info page\", \"This is a Facial Recognition System able to detect new faces real-time made by:\\nAdham Hossam - E-mail: A.Hossammahmoud2164@nu.edu.eg \\nAmro Hossam \\nShahd Hamdy \\nAdham Magdy\")\n",
    "\n",
    "b4 = tk.Button(window, text=\"Contact us\", font=(\"Slab serif\",13), bg=\"pink\", fg=\"black\", command = message_box)\n",
    "b4.place(x=0, y=270)\n",
    "\n",
    "window.geometry(\"900x300\")\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bc539c-ae76-403a-a527-c0a443cdadc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf2454e-fd6b-4246-aad7-c232f206fce1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
